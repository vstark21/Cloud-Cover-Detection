---
SEED: 42
VERBOSE: 1

NAME: 'CCD'

MODEL: 'segmenter' # 'cloudnetp', 'unet' or 'segmenter'
NUM_WORKERS: 2
MODEL_PARAMS:
    unet:
        n_channels: 4
        n_classes: 1
        model_size: 'small'
        bilinear: False
    cloudnetp:
        n_channels: 4
        n_classes: 1
        inception_depth: 6
        model_size: 'small'
        residual: True
    segmenter:
        model_cfg:
            d_model: 384
            decoder:
                drop_path_rate: 0.0
                dropout: 0.1
                n_cls: 150
                n_layers: 2
                name: mask_transformer
            distilled: false
            drop_path_rate: 0.1
            dropout: 0.0
            image_size:
                - 512
                - 512
            n_cls: 1
            n_heads: 6
            n_layers: 12
            normalization: vit
            patch_size: 16
            channels: 4

# Data
DATA_PATHS:
    - "data/"
DATA_MEAN: 
    - 2848.06411202
    - 2839.08714853
    - 2741.28910764
    - 3657.90921129
DATA_STD:
    - 3156.92684648 
    - 2899.28014451 
    - 2789.96160889 
    - 2424.18942846
MODEL_MEAN:
    unet:
        model_mean: 
            - 0.0
            - 0.0
            - 0.0
            - 0.0
        model_std:
            - 1.0
            - 1.0
            - 1.0
            - 1.0    
    cloudnetp:
        model_mean: 
            - 0.0
            - 0.0
            - 0.0
            - 0.0
        model_std:
            - 1.0
            - 1.0
            - 1.0
            - 1.0
    segmenter:
        model_mean: 
            - 127.5 
            - 127.5 
            - 127.5 
            - 127.5
        model_std: 
            - 127.5 
            - 127.5 
            - 127.5 
            - 127.5
    

# Loss
BCE_LW: 0.0
DICE_LW: 1.0
JACC_LW: 1.0
FJACC_LW: 1.0

# Training
OPTIMIZER: 'Adam' # Should be one of the algorithms in https://pytorch.org/docs/stable/optim.html
TRAIN_BATCH_SIZE: 4
EPOCHS: 128
LEARNING_RATE: 5.0e-4
AMP: True
TRAIN_ITERS: 1024
N_ACCUMULATE: 16
MIN_LEARNING_RATE: 1.0e-5
SCHEDULER: "ReduceLROnPlateau" # Should be one of the scheduler in https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
SCHEDULER_PARAMS:
    mode: "min"
    patience: 2
    factor: 0.5

# Validating
VAL_BATCH_SIZE: 4
VAL_ITERS: 512

# Wandb 
USE_WANDB: True

# Outputs
OUTPUT_PATH: 'outputs/'
LOG_FILE: 'outputs/logs.log'
